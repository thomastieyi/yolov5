{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdba7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,imutils\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils.augmentations import letterbox\n",
    "import numpy as np\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.general import (LOGGER, check_img_size,cv2, non_max_suppression, scale_coords)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b13d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(object):\n",
    "    def __init__(self):\n",
    "        if(torch.cuda.is_available()):\n",
    "            self.device = select_device('0')\n",
    "        else:\n",
    "            self.device = select_device('cpu')\n",
    "        self.imgsz=(640, 640)\n",
    "        self.model = DetectMultiBackend('yolov5s.pt', device=self.device, dnn=False)\n",
    "        self.stride, self.names, self.pt, self.jit, self.onnx, self.engine = self.model.stride, self.model.names,self.model.pt, self.model.jit, self.model.onnx, self.model.engine\n",
    "        self.imgsz = check_img_size(self.imgsz, s=self.stride)  # check image size\n",
    "        self.model.warmup(imgsz=(1, 3, *self.imgsz))  # warmup\n",
    "        self.dt, self.seen = [0.0, 0.0, 0.0], 0\n",
    "    \n",
    "    def infer(self,image):        \n",
    "        # cv2.imshow('Original VIDEO',image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        img = letterbox(image, 640, stride=self.stride, auto=True)[0]\n",
    "        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        img = np.ascontiguousarray(img)\n",
    "        \n",
    "\n",
    "        # image = cv2.putText(image,'FPS: '+str(fps),(10,40),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(img).to(self.device)\n",
    "        im = im.half() if self.model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim \n",
    "        t2 = time_sync()\n",
    "        self.dt[0] += t2 - t1\n",
    "        \n",
    "        # Inference\n",
    "        # visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "        pred = self.model(im, augment=False, visualize=False)\n",
    "        t3 = time_sync()\n",
    "        self.dt[1] += t3 - t2 \n",
    "        # s += '%gx%g ' % im.shape[2:]  # print string     \n",
    "        pred = non_max_suppression(pred, 0.25, 0.45, None, False, max_det=1000)\n",
    "        self.dt[2] += time_sync() - t3\n",
    "        for i, det in enumerate(pred): \n",
    "            annotator = Annotator(image, line_width=3, example=str(\"exp\"))\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], image.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    # s += f\"{n} {self.names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):                   \n",
    "                    c = int(cls)  # integer class\n",
    "                    label = None if False else (self.names[c] if False else f'{self.names[c]} {conf:.2f}')\n",
    "                    annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "            im0 = annotator.result()       \n",
    "            im0 = cv2.putText(im0,'FrameDelay: '+str(round(((time_sync() - t1)*1000), 1))+\" ms\",(10,40),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "            # ret, jpeg = cv2.imencode('.jpg', im0,[cv2.IMWRITE_JPEG_QUALITY,60])\n",
    "            \n",
    "            return im0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6b55f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v6.1-291-g2b227d2 Python-3.9.12 torch-1.12.0 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s_v6 summary: 213 layers, 7225885 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "filePath='rtmp://103.85.20.95:1935/live/VR'\n",
    "Infer =  Inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e775938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "AIUrl = 'http://192.168.0.115:8081/AI' #这里改成本地ip，端口号不变，文件夹自定义\n",
    "VRUrl = 'http://192.168.0.115:8081/VR' #这里改成本地ip，端口号不变，文件夹自定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29349f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(filePath) \n",
    "size = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)), int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "sizeStr = str(size[0]) + 'x' + str(size[1])\n",
    "fps = camera.get(cv2.CAP_PROP_FPS)  # 30p/self\n",
    "fps = int(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce82903",
   "metadata": {},
   "outputs": [],
   "source": [
    "commandAI = [\n",
    "    'ffmpeg',\n",
    "    # 're',#\n",
    "    # '-y', # 无需询问即可覆盖输出文件\n",
    "    '-f', 'rawvideo', # 强制输入或输出文件格式\n",
    "    '-vcodec','rawvideo', # 设置视频编解码器。这是-codec:v的别名\n",
    "    '-pix_fmt', 'bgr24', # 设置像素格式\n",
    "    '-s', sizeStr, # 设置图像大小\n",
    "    '-r', str(fps), # 设置帧率\n",
    "    '-i', '-', # 输入\n",
    "    '-c:v', 'mpeg1video',\n",
    "    # '-pix_fmt', 'yuv420p',\n",
    "    '-r', str(fps), # 设置帧率\n",
    "    # '-preset', 'ultrafast',\n",
    "    '-f', 'mpegts',# 强制输入或输出文件格式\n",
    "    AIUrl]\n",
    "commandVR = [\n",
    "    'ffmpeg',\n",
    "    # 're',#\n",
    "    # '-y', # 无需询问即可覆盖输出文件\n",
    "    '-f', 'rawvideo', # 强制输入或输出文件格式\n",
    "    '-vcodec','rawvideo', # 设置视频编解码器。这是-codec:v的别名\n",
    "    '-pix_fmt', 'bgr24', # 设置像素格式\n",
    "    '-s', sizeStr, # 设置图像大小\n",
    "    '-r', str(fps), # 设置帧率\n",
    "    '-i', '-', # 输入\n",
    "    '-c:v', 'mpeg1video',\n",
    "    # '-pix_fmt', 'yuv420p',\n",
    "    '-r', str(fps), # 设置帧率\n",
    "    # '-preset', 'ultrafast',\n",
    "    '-f', 'mpegts',# 强制输入或输出文件格式\n",
    "    VRUrl]\n",
    "pipeAI = sp.Popen(commandAI, stdin=sp.PIPE)\n",
    "pipeVR = sp.Popen(commandVR, stdin=sp.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "while (True):\n",
    "    ret, frame = camera.read() # 逐帧采集视频流\n",
    "    if not ret:\n",
    "        camera = cv2.VideoCapture(filePath) \n",
    "        continue\n",
    "    img = Infer.infer(copy.deepcopy(frame))\n",
    "    pipeAI.stdin.write(img.tobytes())\n",
    "    pipeVR.stdin.write(frame.tobytes() )\n",
    "    ############################图片输出\n",
    "    # 结果帧处理 存入文件 / 推流 / ffmpeg 再处理\n",
    "#     pipe.stdin.write(frame.tostring())  # 存入管道用于直播\n",
    "    # out.write(frame)    #同时 存入视频文件 记录直播帧数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45401bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f982e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
